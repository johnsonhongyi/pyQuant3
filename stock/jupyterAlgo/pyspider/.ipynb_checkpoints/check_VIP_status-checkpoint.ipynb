{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tentcent VIP check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load vip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T10:43:25.400174Z",
     "start_time": "2019-05-05T10:43:25.372714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locallist:701 ﻿捉迷藏;2016年\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "r_root ='/Users/Johnson/Downloads/iyanshu/feichi/'\n",
    "res_disk=['disk1','disk2','disk3','disk4','disk5']\n",
    "res_disk=['vip2']\n",
    "def get_file_list(f_path,encoding='utf8',sep=None):\n",
    "    fout = io.open(f_path, 'rU',encoding=encoding).readlines()\n",
    "    f_list =[]\n",
    "    if not sep:\n",
    "        for m in fout:\n",
    "            count_list = m.split('.')\n",
    "            if len(count_list) <2:\n",
    "                f_list.append(m.strip())\n",
    "            else:\n",
    "                f_list.append(m.split('.')[:-1][0].strip())\n",
    "    else:\n",
    "        for m in fout:\n",
    "#             print m.split(sep)[0]\n",
    "            f_list.append(m.split(sep)[0].strip()+';'+m.split(sep)[1].strip())\n",
    "    return f_list\n",
    "local_list=[]\n",
    "for f in res_disk:\n",
    "    f_p = r_root+f+'.csv'\n",
    "    data_list = get_file_list(f_p,encoding='utf8',sep=';')\n",
    "    local_list.extend(data_list)\n",
    "print \"locallist:%s %s\"%(len(local_list),local_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check vip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T08:52:18.725406Z",
     "start_time": "2019-10-14T08:52:18.606493Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'local_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9eeab77e62d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# local_list=[u'火海凌云;2016年',u'阿尔及尔之战;1966年']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocal_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m445\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0msearch_tencent_VIP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'年'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m#     search_tencent_VIP(title.split(';')[0].encode('utf8'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'local_list' is not defined"
     ]
    }
   ],
   "source": [
    "#### -*- coding:utf-8 -*-\n",
    "import urllib2\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib2 import quote, unquote\n",
    "import time\n",
    "\n",
    "root_url ='https://v.qq.com/x/search/?q=%s&stag=0&smartbox_ab='\n",
    "# search_url = root_url%('国产凌凌漆')\n",
    "\n",
    "def search_tencent_VIP(title,year=None):\n",
    "    print \"Sh:%s year:%s\"%(title.strip(),year)\n",
    "    search_url = root_url%(title.strip())\n",
    "    # print search_url\n",
    "    # print urllib2.quote(\"http://192.168.10.105:8080/media/activities/上海/ad/1515043837.jpg\")\n",
    "    # help(quote)?\n",
    "    search_url = quote(search_url, safe=\";/?:@&=+$,\")\n",
    "    # print \"quote_url:%s\"%(search_url)\n",
    "    html = urllib2.urlopen(search_url)\n",
    "    html_data = html.read()\n",
    "    soup = BeautifulSoup(html_data, 'html.parser')\n",
    "    # print soup\n",
    "#     content = soup.find(\"div\", {\"class\":\"_infos\"}).find_all(\"span\",{\"class\":\"mark_v\"})\n",
    "    content = soup.find_all(\"div\", {\"class\":\"_infos\"})\n",
    "#     _playlist = soup.find(\"div\", {\"class\":\"_playlist\"}).find_all(\"i\",{\"class\":\"icon_sm icon_play_sm\"})\n",
    "#     content_playlist = soup.find_all(\"div\", {\"class\":\"_playlist\"})\n",
    "    content_playsrc = soup.find_all(\"div\", {\"class\":\"_playsrc\"})\n",
    "    \n",
    "#     (\"span\",{\"class\":\"icon_text\"})\n",
    "    \n",
    "#     print len(content),len(content_playlist)\n",
    "    # content_Vip = soup.find(\"div\", {\"class\":\"_infos\"}).find_all(\"span\",{\"class\":\"mark_v\"})\n",
    "    # .find_all(\"span\",{\"class\":\"_infos\"})\n",
    "\n",
    "    # if content:\n",
    "    #     print \"VIP\"\n",
    "    # else:\n",
    "    #     print \"Free\"\n",
    "    find_ok = 0\n",
    "    for idx, con in enumerate(content):\n",
    "        type_l = con.find(\"span\", {\"class\":\"type\"}).get_text()\n",
    "        if type_l==u'电影':\n",
    "    #         print con.find(\"em\", {\"class\":\"hl\"}).find(\"span\", {\"class\":\"sub\"})\n",
    "    #         print con.find(\"div\", {\"class\":\"_infos\"}).find(\"em\", {\"class\":\"hl\"})\n",
    "#             print con.find(\"em\", {\"class\":\"hl\"}) ,con.find(\"span\", {\"class\":\"sub\"})\n",
    "            tt_S = con.find(\"em\", {\"class\":\"hl\"})\n",
    "            tt_O = con.find(\"span\", {\"class\":\"sub\"})\n",
    "#             print con\n",
    "#             print content_playlist[idx].find(\"span\",{\"class\":\"icon_text\"}).get_text()\n",
    "#             print len(content_playsrc),idx\n",
    "            src_idx = idx if len(content_playsrc) > idx else 0\n",
    "#             print src_idx\n",
    "            playsrc = content_playsrc[src_idx].find(\"span\",{\"class\":\"icon_text\"})\n",
    "            if playsrc is not None:\n",
    "                playsrc = playsrc.get_text().strip()\n",
    "                \n",
    "#             print tt_S,tt_O\n",
    "        \n",
    "            if tt_S and tt_O:\n",
    "                if title.decode('utf8') == (tt_S.get_text().strip()):\n",
    "                    if year:\n",
    "                        if tt_O.get_text().find(year) > 0:\n",
    "                            find_ok +=1\n",
    "                            print \"ST:%s  TT:%s Year:%s\"%(title.decode('utf8'),tt_S.get_text().strip() ,tt_O.get_text().strip()),\n",
    "                            Vip_s =  con.find(\"span\", {\"class\":\"mark_v\"})\n",
    "                            if playsrc:\n",
    "                                if playsrc == (u'腾讯视频') :\n",
    "                                    print \"idx: %s type:%s    : %s %s\"%(idx,type_l,'VIP' if (Vip_s) is not None else u'免费',playsrc )\n",
    "                                else:\n",
    "                                    print \"\\t\\t : No %s\"%(playsrc)\n",
    "                            break\n",
    "                            \n",
    "                    else:\n",
    "                            find_ok +=1\n",
    "                            print \"ST:%s  TT:%s Year:%s\"%(title.decode('utf8'),tt_S.get_text().strip() ,tt_O.get_text().strip()),\n",
    "                            Vip_s =  con.find(\"span\", {\"class\":\"mark_v\"}) \n",
    "                            if playsrc:\n",
    "                                if playsrc == (u'腾讯视频') :\n",
    "                                    print \"idx: %s type:%s    : %s %s\"%(idx,type_l,'VIP' if (Vip_s) is not None else u'免费',playsrc )\n",
    "                                else:\n",
    "                                    print \"\\t\\t : No %s\"%(playsrc)\n",
    "#                 else:\n",
    "#                     tt_S , tt_O\n",
    "#             else:\n",
    "#                 print tt_S , tt_O\n",
    "    if year:\n",
    "        if find_ok == 0:\n",
    "            search_tencent_VIP(title)\n",
    "        \n",
    "    \n",
    "    \n",
    "    #     print \"con:%s %s\"%(idx,con)\n",
    "    # print content\n",
    "\n",
    "# local_list=[u'火海凌云;2016年',u'阿尔及尔之战;1966年']    \n",
    "    \n",
    "for title in local_list[445:]:\n",
    "    search_tencent_VIP(title.split(';')[0].encode('utf8'),title.split(';')[1].replace(u'年','').encode('utf8'))\n",
    "#     search_tencent_VIP(title.split(';')[0].encode('utf8'))\n",
    "#     break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T15:01:37.803796Z",
     "start_time": "2019-04-30T15:01:37.799571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爱奇艺付费 普通话版 下载客户端，\n"
     ]
    }
   ],
   "source": [
    "print u'\\u7231\\u5947\\u827a\\u4ed8\\u8d39',u'\\u666e\\u901a\\u8bdd\\u7248',u'\\u4e0b\\u8f7d\\u5ba2\\u6237\\u7aef\\uff0c'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T08:57:47.097169Z",
     "start_time": "2019-10-14T08:57:46.489383Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://movie.douban.com/subject_search?search_text=功夫\n",
      "<div id=\"wrapper\">\n",
      "<div class=\"root\" id=\"root\">\n",
      "<div class=\"search-title\">正在搜索...</div>\n",
      "</div>\n",
      "<div id=\"browser-support\"></div>\n",
      "<div id=\"footer\">\n",
      "<span class=\"fleft gray-link\" id=\"icp\">\n",
      "    © 2005－2019 douban.com, all rights reserved 北京豆网科技有限公司\n",
      "</span>\n",
      "<a href=\"https://www.douban.com/hnypt/variformcyst.py\" style=\"display: none;\"></a>\n",
      "<span class=\"fright\">\n",
      "<a href=\"https://www.douban.com/about\">关于豆瓣</a>\n",
      "    · <a href=\"https://www.douban.com/jobs\">在豆瓣工作</a>\n",
      "    · <a href=\"https://www.douban.com/about?topic=contactus\">联系我们</a>\n",
      "    · <a href=\"https://www.douban.com/about/legal\">法律声明</a>\n",
      "    \n",
      "    · <a href=\"https://help.douban.com/?app=main\" target=\"_blank\">帮助中心</a>\n",
      "    · <a href=\"https://www.douban.com/doubanapp/\">移动应用</a>\n",
      "    · <a href=\"https://www.douban.com/partner/\">豆瓣广告</a>\n",
      "</span>\n",
      "</div>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\"\"\"\n",
    " 获取豆瓣电影评分排行榜\n",
    "\"\"\"\n",
    "import urllib2\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# 获得指定开始排行的电影url\n",
    "def get_url(root_url,start):\n",
    "    return root_url+\"?start=\"+str(start)+\"&filter=\"\n",
    "\n",
    "def get_review(page_url):\n",
    "    movies_list=[]\n",
    "    response=requests.get(page_url)\n",
    "    soup=BeautifulSoup(response.text,\"lxml\")\n",
    "    soup=soup.find('ol','grid_view')\n",
    "    for tag_li in soup.find_all('li'):\n",
    "        dict={}\n",
    "        dict['rank']=tag_li.find('em').string\n",
    "        dict['name']=tag_li.find_all('span','title')[0].string\n",
    "        dict['score']=tag_li.find('span','rating_num').string\n",
    "        if(tag_li.find('span','inq')):\n",
    "            dict['desc']=tag_li.find('span','inq').string\n",
    "        movies_list.append(dict)\n",
    "    return movies_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     root_url=\"https://movie.douban.com/top250\"\n",
    "    root_url = \"https://movie.douban.com/subject_search?search_text=%s\"\n",
    "#     root_url = \"https://search.douban.com/movie/subject_search?search_text=%s&cat=1002\"\n",
    "#     raw_in = raw_input(\"name:\")\n",
    "    raw_in = '功夫'\n",
    "    \n",
    "    if raw_in is not None:\n",
    "        root_url = root_url%(raw_in)\n",
    "        print root_url\n",
    "        html = urllib2.urlopen(root_url)\n",
    "        html_data = html.read()\n",
    "        soup = BeautifulSoup(html_data, 'html.parser')\n",
    "#         print soup\n",
    "        content = soup.find(\"div\", {\"id\":\"wrapper\"})\n",
    "        if content:\n",
    "            print content\n",
    "        else:\n",
    "            print \"None\"\n",
    "\n",
    "\n",
    "    #     start=0\n",
    "#     while(start<250):\n",
    "#         movies_list=get_review(get_url(root_url,start))\n",
    "#         for movie_dict in movies_list:\n",
    "#             print(u'电影排名：'+movie_dict['rank'])\n",
    "#             print(u'电影名称：'+movie_dict.get('name'))\n",
    "#             print(u'电影评分：'+movie_dict.get('score'))\n",
    "#             print(u'电影评词：'+movie_dict.get('desc',u'无评词'))\n",
    "#             print('------------------------------------------------------')\n",
    "#         start+=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "douban_root='https://movie.douban.com/subject_search?search_text=%s&cat=1002'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# douban"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T09:05:31.795840Z",
     "start_time": "2019-10-14T09:05:31.148991Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://movie.douban.com/subject/27166976/\n",
      "安娜 (豆瓣)\n",
      "director : 吕克·贝松\n",
      "actor : 萨莎·露丝,海伦·米伦,卢克·伊万斯,基里安·墨菲,莱拉·阿波瓦,亚历山大·佩特罗夫\n",
      "故事聚焦神秘女杀手安娜的成长及执行各种暗杀任务的经历，在美丽的外表下，安娜拥有聪明绝顶的头脑和强大的战斗技巧，是世界上最恐怖的刺客之一，她游走于黑白两道，只要被锁定的目标，从不失手。\n",
      "description : 故事聚焦神秘女杀手安娜的成长及执行各种暗杀任务的经历，在美丽的外表下，安娜拥有聪明绝顶的头脑和强大的战斗技巧，是世界上最恐怖的刺客之一，她游走于黑白两道，只要被锁定的目标，从不失手。\n",
      "aggregateRating : 7.7\n"
     ]
    }
   ],
   "source": [
    "#### -*- coding:utf-8 -*-\n",
    "import urllib2\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib2 import quote, unquote\n",
    "import time\n",
    "import re\n",
    "\n",
    "root_url ='https://movie.douban.com/subject/%s/'\n",
    "      \n",
    "def search_douban_VIP(search_url):    \n",
    "    html = urllib2.urlopen(search_url)\n",
    "    html_data = html.read()\n",
    "    soup = BeautifulSoup(html_data, 'html.parser')\n",
    "    print soup.find_all(\"视频)\n",
    "    content = soup.find_all(\"title\")\n",
    "    if content:\n",
    "        print content[0].get_text().strip()\n",
    "        cont = soup.find(\"script\", {\"type\":\"application/ld+json\"})\n",
    "        mvdict = {}\n",
    "        if cont :\n",
    "#             print cont.get_text()\n",
    "            cont_dic = eval(cont.contents[0])\n",
    "        \n",
    "            def get_cont_dic(cont_dic,mvdict,key):\n",
    "                director = (cont_dic[key])\n",
    "            \n",
    "                if key in ['director','author','actor']:\n",
    "                    if len(director) > 1:\n",
    "                        d_name = ''\n",
    "                        for x in director:\n",
    "                            if len(d_name) > 2:\n",
    "                                if len(d_name.split(',')) < 6:\n",
    "                                    d_name = d_name +','+(dict(x)['name'].split()[0])\n",
    "                                else:\n",
    "                                    break\n",
    "                            else:\n",
    "                                d_name = (dict(x)['name'].split()[0])\n",
    "#                             print d_name,dict(x)['name'].split()[0]\n",
    "                        mvdict[key] = d_name\n",
    "                    else:\n",
    "#                         print dict(director[0])['name'].split()[0]\n",
    "                        mvdict[key] = dict(director[0])['name'].split()[0]\n",
    "#                     if key == 'actor':\n",
    "#                         if (mvdict[key].split(',')) > 5:\n",
    "#                             continue\n",
    "                elif key in ['description']:\n",
    "                    print director\n",
    "                    mvdict[key] =  director.strip()\n",
    "                elif key in ['aggregateRating']:\n",
    "#                     print dict(director)['ratingValue']\n",
    "                    mvdict[key] = dict(director)['ratingValue']  \n",
    "            \n",
    "                return mvdict\n",
    "\n",
    "#             for key in ['director','author','actor','description','aggregateRating']:\n",
    "            for key in ['director','actor','description','aggregateRating']:\n",
    "                mvdict = get_cont_dic(cont_dic,mvdict,key)\n",
    "                print \"%s : %s\"%(key,mvdict[key])\n",
    "#             print  mvdict\n",
    "#         print  re_script.sub('',cont) #去掉SCRIPT\n",
    "#     _playlist = soup.find(\"div\", {\"class\":\"_playlist\"}).find_all(\"i\",{\"class\":\"icon_sm icon_play_sm\"})\n",
    "#     content_playlist = soup.find_all(\"div\", {\"class\":\"_playlist\"})\n",
    "#     content_playsrc = soup.find_all(\"div\", {\"class\":\"_playsrc\"})\n",
    "\n",
    "while 1:\n",
    "#     file_name = raw_input(\"输入douban:\")\n",
    "    file_name = '27166976'\n",
    "    print \"url: %s\"%(root_url%file_name)\n",
    "    search_douban_VIP(root_url%file_name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test search_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T17:52:47.405810Z",
     "start_time": "2019-05-13T17:52:46.363780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please input the name of film u want to search:\n",
      "film_name:天下无贼\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-fb6a742aa2f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<a class=\"nbg\" href=\"(.+?)\" >'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# print html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmovie_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\D+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmovie_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    " \n",
    "import urllib,re,json\n",
    " \n",
    "#movie:\n",
    "     #search engine:http://movie.douban.com/subject_search?search_text=+film_name+&cat=1002\n",
    "     #info:https://api.douban.com/v2/movie/:id\n",
    " \n",
    "print(\"please input the name of film u want to search:\")\n",
    "# film_name = raw_input()\n",
    "film_name = u'天下无贼'.encode(\"utf-8\")\n",
    "movie_search_engine = \"http://movie.douban.com/subject_search?search_text=\"+film_name+\"&cat=1002\"\n",
    "print \"film_name:%s\"%(film_name)\n",
    "movie_search = movie_search_engine\n",
    "html = urllib.urlopen(movie_search).read()\n",
    "match = re.findall('<a class=\"nbg\" href=\"(.+?)\" >',html)\n",
    "# print html\n",
    "match = match[0]\n",
    "movie_id = re.split(r'\\D+',match)\n",
    "movie_id = movie_id[1]\n",
    "movie_url = \"https://api.douban.com/v2/movie/\"+movie_id\n",
    "movie_url = urllib.urlopen(movie_url).read()\n",
    "jsondata = json.loads(movie_url)\n",
    "name = jsondata[\"alt_title\"]\n",
    "rate = jsondata[\"rating\"][\"average\"]\n",
    "director = jsondata[\"attrs\"][\"director\"][0]\n",
    "cast = jsondata[\"attrs\"][\"cast\"]\n",
    "pubdate = jsondata[\"attrs\"][\"pubdate\"][0]\n",
    "movie_duration = jsondata[\"attrs\"][\"movie_duration\"][0]\n",
    "country = jsondata[\"attrs\"][\"country\"][0]\n",
    "movie_type = jsondata[\"attrs\"][\"movie_type\"]\n",
    "print(\"name:\" + name)\n",
    "print(\"rate:\" + rate)\n",
    "print(\"director:\" + director)\n",
    "print(\"casts:\" + cast[0] +\"\\\\\"+ cast[1] +\"\\\\\"+ cast[2])\n",
    "print(\"country:\" + country)\n",
    "print(\"duration:\" + movie_duration)\n",
    "print(\"pubdate:\" + pubdate)\n",
    "print(\"country:\" + movie_type[0] +\"\\\\\"+ movie_type[1] +\"\\\\\"+ movie_type[2])\n",
    "print(\"--------------------------------------------------------By Douban\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T16:27:36.460253Z",
     "start_time": "2019-05-13T16:27:35.924087Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from urllib.request import urlopen, Request\n",
    "except ImportError:\n",
    "    from urllib2 import urlopen, Request\n",
    "import requests\n",
    "import ssl\n",
    "import json\n",
    "\n",
    "def ajaxCrawler(url):\n",
    "    headers = {\n",
    "        \"User-Agent\":\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Maxthon/4.4.3.4000 Chrome/30.0.1599.101 Safari/537.36\"\n",
    "    }\n",
    "    req = Request(url, headers=headers)\n",
    "\n",
    "    # 使用ssl创建未验证的上下文\n",
    "    context = ssl._create_unverified_context()\n",
    "\n",
    "\n",
    "    response = urlopen(req,context=context)\n",
    "\n",
    "    jsonStr = response.read().decode(\"utf-8\")\n",
    "#     jsonData = json.loads(jsonStr)\n",
    "    return jsonStr\n",
    "\n",
    "# url = \"https://movie.douban.com/j/chart/top_list?type=11&interval_id=100%3A90&action=&start=0&limit=20\"\n",
    "url = 'https://movie.douban.com/subject_search?search_text=%E5%8A%9F%E5%A4%AB%E4%B9%8B%E7%8E%8B'\n",
    "info = ajaxCrawler(url)\n",
    "# print(info)\n",
    "# --------------------- \n",
    "# 作者：aspiring123 \n",
    "# 来源：CSDN \n",
    "# 原文：https://blog.csdn.net/qq_39198486/article/details/81503383 \n",
    "# 版权声明：本文为博主原创文章，转载请附上博文链接！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "330px",
    "left": "2px",
    "right": "1254px",
    "top": "106px",
    "width": "139px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
