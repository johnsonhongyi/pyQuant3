import os
import logging
from typing import List, Dict, Any, Optional
import pandas as pd
from datetime import datetime

from strategy_interface import IStrategy, StrategyConfig, StrategyMode
from signal_types import SignalPoint, SignalType, SignalSource
from signal_message_queue import SignalMessageQueue, SignalMessage

logger = logging.getLogger(__name__)

class StrongConsolidationStrategy(IStrategy):
    """
    å¼ºåŠ¿æ•´ç†çªç ´ç­–ç•¥ (301348æ¨¡å¼)
    
    é€»è¾‘:
    1. å¯»æ‰¾æœ€è¿‘ä¸€æ¬¡ä¸­é˜³çªç ´å¸ƒæ—ä¸Šè½¨ (Breakout Day)
    2. æ£€æŸ¥è‡ªBreakout Dayä»¥æ¥, æ”¶ç›˜ä»·ä»æœªæœ‰æ•ˆè·Œç ´ Breakout Day çš„æ”¶ç›˜ä»· (Strong Consolidation)
    3. æ£€æŸ¥æœ€è¿‘2æ—¥æ˜¯å¦å‘ˆç°æ”»å‡»å½¢æ€ (æ¯æ—¥æ–°é«˜, é‡èƒ½é…åˆ)
    """
    
    def __init__(self, config: Optional[StrategyConfig] = None):
        super().__init__(config)
        if not self._config.description:
            self._config.description = "æ•æ‰å¼ºåŠ¿æ•´ç†åå†æ¬¡çªç ´çš„ä¸ªè‚¡ (å¦‚301348æ¨¡å¼)"
        
        # å†…éƒ¨ä½¿ç”¨ SignalMessageQueue æ¨é€ä¿¡å·
        try:
            from signal_message_queue import SignalMessageQueue
            self.queue = SignalMessageQueue()
        except:
            self.queue = None

    def evaluate_historical(self, code: str, day_df: pd.DataFrame) -> List[SignalPoint]:
        # æœ¬ç­–ç•¥ä¸»è¦ç”¨äºå®æ—¶ç›‘æ§å’Œå³æ—¶é€‰è‚¡, å†å²å›æµ‹æš‚è¿”å›ç©ºæˆ–ä»…ä½œä¸ºéªŒè¯
        # ä¸ºç®€åŒ–, è¿™é‡Œæš‚ä¸å®ç°å…¨å†å²å›æµ‹é€»è¾‘, ä»…å¯¹æœ€åä¸€å¤©è¿›è¡Œè¯„ä¼°
        points = []
        if day_df is None or len(day_df) < 20: 
            return points
            
        # æ¨¡æ‹Ÿå®æ—¶è¯„ä¼°æœ€åä¸€è¡Œ
        # last_row = day_df.iloc[-1].to_dict()
        # snapshot = {
        #     'trade': last_row['close'],
        #     'high': last_row['high'],
        #     'low': last_row['low'],
        #     'open': last_row['open'],
        #     'volume': last_row['volume']
        # }
        
        # éœ€è¦ä¼ å…¥å®Œæ•´DFè¿›è¡Œè®¡ç®—
        sig = self._detect_pattern(code, day_df)
        if sig:
            points.append(sig)
            
            # --- å¢å¼º: å®æ—¶æ¨é€é€»è¾‘ (æ”¯æŒæ‰‹åŠ¨åˆ‡æ¢è‚¡ç¥¨è§¦å‘) ---
            # å¦‚æœä¿¡å·æ˜¯"ä»Šå¤©"(æœ€åä¸€è¡Œ)è§¦å‘çš„, æ¨é€åˆ°æ¶ˆæ¯é˜Ÿåˆ—
            try:
                # ç®€å•åˆ¤æ–­: ä¿¡å·æ—¶é—´æ˜¯æ•°æ®æœ€åä¸€è¡Œçš„æ—¶é—´
                if str(sig.timestamp) == str(day_df.index[-1]) and self.queue:
                    # é¿å…é‡å¤æ¨é€? SignalMessageQueueæœªå»é‡, ä½†UIæ˜¾ç¤ºæœ‰é™åˆ¶
                    # æ„é€ æ¶ˆæ¯
                    msg = SignalMessage(
                        priority=20, 
                        timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        code=code,
                        name=str(day_df.iloc[-1].get('name', '')), 
                        signal_type='CONSOLIDATION',
                        source='STRATEGY',
                        reason=sig.reason,
                        score=90
                    )
                    self.queue.push(msg)
            except Exception as e:
                logger.error(f"Failed to push signal in evaluate_historical: {e}")
            
        return points

    def evaluate_realtime(self, code: str, row_data: Dict[str, Any], 
                          snapshot: Dict[str, Any]) -> Optional[SignalPoint]:
        """å®æ—¶è¯„ä¼°"""
        # æ³¨æ„: å®æ—¶è¯„ä¼°é€šå¸¸åªæ‹¿åˆ°å½“å‰tick, éœ€è¦å†å²æ•°æ®é…åˆ
        # æ­¤å¤„å‡è®¾è°ƒç”¨æ–¹ä¼šæä¾›è¶³å¤Ÿçš„å†å²æ•°æ®ä¸Šä¸‹æ–‡, æˆ–è€…æˆ‘ä»¬åœ¨å†…éƒ¨ç»´æŠ¤/è·å–
        # å®é™…ä¸Š StrategyController è°ƒç”¨ evaluate_realtime æ—¶é€šå¸¸æ˜¯ Tick çº§
        # å¯¹äºå½¢æ€ç­–ç•¥, æˆ‘ä»¬æ›´å€¾å‘äºåœ¨ on_dataframe_updated (åˆ†é’Ÿ/æ—¥çº¿æ›´æ–°) æ—¶è§¦å‘
        # ä½†éµå¾ªæ¥å£, æˆ‘ä»¬å¯ä»¥åšç®€å•çš„åˆ¤è¯», æˆ–è€…ä¾èµ–å¤–éƒ¨ä¼ å…¥çš„ day_df (å¦‚æœæ¥å£æ”¯æŒ)
        
        # ä¿®æ­£: æ ‡å‡†æ¥å£ evaluate_realtime åªæœ‰ row_data/snapshot
        # ä¸¥æ ¼æ¥è¯´æ— æ³•åšåŸºäºå†å²å½¢æ€çš„å¤æ‚åˆ¤æ–­. 
        # æœ¬ç­–ç•¥æ›´é€‚åˆä½œä¸º "é€‰è‚¡å™¨" è¿è¡Œ, æˆ–åœ¨ StrategyController è·å–åˆ°æ–°Kçº¿æ—¶è¿è¡Œ.
        # 
        # æš‚æ—¶è¿”å› None, é€»è¾‘ä¸»è¦å®ç°åœ¨ evaluate_historical (è¢«å‘¨æœŸæ€§è°ƒç”¨) 
        # æˆ–é€šè¿‡å¤–éƒ¨ç‹¬ç«‹è°ƒç”¨æ£€æµ‹.
        return None
        
    def detect_and_push(self, code: str, df: pd.DataFrame) -> bool:
        """
        ä¸»åŠ¨æ£€æµ‹å¹¶æ¨é€ä¿¡å· (ä¾›å¤–éƒ¨å‘¨æœŸæ€§è°ƒç”¨)
        """
        sig_point = self._detect_pattern(code, df)
        if sig_point:
            # æ¨é€åˆ°æ¶ˆæ¯é˜Ÿåˆ—
            if self.queue:
                msg = SignalMessage(
                    priority=20, # è¾ƒé«˜ä¼˜å…ˆçº§
                    timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    code=code,
                    name=str(df.iloc[-1].get('name', '')), # å°è¯•è·å–åç§°
                    signal_type='CONSOLIDATION',
                    source='STRATEGY',
                    reason=sig_point.reason,
                    score=90
                )
                self.queue.push(msg)
                return True
        return False

    def execute_scan(self, df_all: pd.DataFrame, resample: str = 'd', parallel: bool = True) -> List[Dict[str, Any]]:
        """
        å…¨å¸‚åœºæ‰¹é‡æ‰«æç¬¦åˆå¼ºåŠ¿æ•´ç†æ¨¡å¼çš„ä¸ªè‚¡
        :param df_all: å¦‚æœæ˜¯å®æ—¶æ•°æ®ï¼Œé€šå¸¸æ˜¯ indexed by code çš„ DataFrameï¼›å¦‚æœæ˜¯å†å²æ•°æ®ï¼Œå¯èƒ½æ˜¯ MultiIndex (date, code)
        :param resample: å‘¨æœŸ
        :param parallel: æ˜¯å¦å¼€å¯å¹¶è¡ŒåŠ é€Ÿ
        :return: æ‰«æç»“æœåˆ—è¡¨
        """
        results = []
        # æ³¨æ„: è¿™é‡Œçš„ df_all å‡è®¾åŒ…å«äº†ä¸€å®šå†å²æ·±åº¦çš„Kçº¿æ•°æ® (MultiIndex æˆ–è€…æŒ‰ä»£ç åˆ†ç‰‡çš„åˆ—è¡¨)
        # å¦‚æœ df_all ä»…æ˜¯å•è¡Œå¿«ç…§ï¼Œåˆ™æ— æ³•è¿›è¡Œå½¢æ€è¯†åˆ«
        
        # ä¸ºäº†æ¼”ç¤ºå’Œæ¥å£å¯¹é½ï¼Œæˆ‘ä»¬å‡è®¾ df_all æ˜¯æŒ‰ä»£ç åˆ†ç‰‡çš„å­—å…¸ï¼Œæˆ–è€…æˆ‘ä»¬å¯ä»¥æŒ‰ä»£ç åˆ†ç»„å¤„ç†
        if not isinstance(df_all, pd.DataFrame) or df_all.empty:
            return []

        # è·å–æ‰€æœ‰ä»£ç 
        if 'code' in df_all.columns:
            codes = df_all['code'].unique()
        elif isinstance(df_all.index, pd.MultiIndex):
            codes = df_all.index.get_level_values('code').unique()
        else:
            # å‡è®¾ index å°±æ˜¯ code (TDX å¸¸è§æ ¼å¼)
            codes = df_all.index.unique()

        logger.info(f"ğŸš€ Starting Strong Consolidation scan for {len(codes)} stocks (resample={resample}, parallel={parallel})...")

        if parallel and len(codes) > 50:
            from concurrent.futures import ThreadPoolExecutor, as_completed
            with ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:
                # é¢„åˆ‡ç‰‡
                def _get_sub_df(c):
                    if isinstance(df_all.index, pd.MultiIndex):
                        if 'code' in df_all.index.names:
                            return df_all.xs(c, level='code')
                        else:
                            return df_all.loc[(slice(None), c)]
                    else:
                        if 'code' in df_all.columns:
                            return df_all[df_all['code'] == c]
                        else:
                            return df_all[df_all.index == c]

                futures = {executor.submit(self._detect_pattern, str(c), _get_sub_df(c)): c for c in codes}
                for future in as_completed(futures):
                    code = futures[future]
                    try:
                        sig = future.result()
                        if sig:
                            sub_df = _get_sub_df(code)
                            results.append({
                                'code': sig.code,
                                'name': str(sub_df.get('name', '')) if not isinstance(sub_df.index, pd.MultiIndex) else str(sub_df['name'].iloc[-1]),
                                'score': 90,
                                'resample': resample,
                                'reason': sig.reason,
                                'price': sig.price,
                                'timestamp': sig.timestamp
                            })
                    except Exception as e:
                        logger.error(f"Scan failed for {code}: {e}")
        else:
            for code in codes:
                try:
                    # ç®€å•åˆ†ç‰‡é€»è¾‘
                    if isinstance(df_all.index, pd.MultiIndex):
                        if 'code' in df_all.index.names:
                            sub_df = df_all.xs(code, level='code')
                        else:
                            sub_df = df_all.loc[(slice(None), code)]
                    else:
                        if 'code' in df_all.columns:
                            sub_df = df_all[df_all['code'] == code]
                        else:
                            sub_df = df_all[df_all.index == code]
                        
                    sig = self._detect_pattern(str(code), sub_df)
                    if sig:
                        results.append({
                            'code': sig.code,
                            'name': str(sub_df.get('name', '')) if not isinstance(sub_df.index, pd.MultiIndex) else str(sub_df['name'].iloc[-1]),
                            'score': 90,
                            'resample': resample,
                            'reason': sig.reason,
                            'price': sig.price,
                            'timestamp': sig.timestamp
                        })
                except Exception as e:
                    logger.debug(f"Scan skip for {code}: {e}")

        logger.info(f"âœ… Scan completed. Found {len(results)} matches.")
        return results

    def _detect_pattern(self, code: str, df: pd.DataFrame) -> Optional[SignalPoint]:
        """
        æ ¸å¿ƒå½¢æ€æ£€æµ‹é€»è¾‘ (ä¼˜åŒ–ç‰ˆ)
        ç»“åˆ å¯åŠ¨å¼ºåº¦(Breakout) + æ”¯æ’‘éªŒè¯(MA Support) + è“„åŠ¿å½¢æ€(Doji/Volume)
        """
        if df is None or len(df) < 30: return None
        
        try:
            # 1. ç¡®ä¿å¿…è¦æŒ‡æ ‡è®¡ç®— (ä¼˜å…ˆä½¿ç”¨å·²æœ‰çš„)
            df = df.copy()
            close_s = pd.to_numeric(df['close'], errors='coerce')
            
            if 'ma5' not in df.columns: df['ma5'] = close_s.rolling(5).mean()
            if 'ma10' not in df.columns: df['ma10'] = close_s.rolling(10).mean()
            if 'ma20' not in df.columns: df['ma20'] = close_s.rolling(20).mean()
            if 'upper' not in df.columns:
                ma20 = close_s.rolling(20).mean()
                std20 = close_s.rolling(20).std()
                df['upper'] = ma20 + 2 * std20
            
            vol_s = pd.to_numeric(df['volume'], errors='coerce')
            df['vol_ma5'] = vol_s.rolling(5).mean()
            df['vol_ma20'] = vol_s.rolling(20).mean()

            # 2. å¯»æ‰¾æœ€è¿‘çš„å¯åŠ¨æ—¥ (Breakout Day) - è¿‡å»3åˆ°20å¤©å†…
            # å¯åŠ¨ç‰¹å¾: çªç ´å¸ƒæ—ä¸Šè½¨, ä¸”ä¸æ˜¯æ”¾å¤©é‡çš„é«˜å¼€ä½èµ°
            recent_search_count = min(len(df), 30)
            recent_search = df.iloc[-recent_search_count:-2].copy() # æœç´¢èŒƒå›´: 3å¤©å‰åˆ°æœ€è¿‘30å¤©å†…
            if recent_search.empty: 
                logger.debug(f"{code}: No recent search data (min 30 days)")
                return None

            # å¯åŠ¨ç‰¹å¾: çªç ´å¸ƒæ—ä¸Šè½¨, ä¸”æ”¶é˜³, æ¶¨å¹…>3%
            recent_search['is_breakout'] = (recent_search['close'] > recent_search['upper']) & \
                                           (recent_search['close'] > recent_search['open']) & \
                                           (recent_search['percent'] > 3)
            
            # å¦‚æœæœ‰ high4, max, hmax æŒ‡æ ‡ï¼Œå¢åŠ çªç ´åˆ¤å®š
            if 'high4' in recent_search.columns:
                recent_search['is_breakout'] |= (recent_search['high'] > recent_search['high4'])
            if 'max' in recent_search.columns:
                recent_search['is_breakout'] |= (recent_search['high'] > recent_search['max'])
            
            # è¿‡æ»¤ breakout
            recent_search = recent_search[recent_search['is_breakout']]
            if recent_search.empty: 
                logger.debug(f"{code}: No breakout found in recent search")
                return None

            # è·å–æœ€è¿‘çš„ä¸€ä¸ªæœ‰æ•ˆå¯åŠ¨æ—¥
            breakout_row = recent_search.iloc[-1]
            breakout_date = breakout_row.name
            breakout_close = float(breakout_row['close'])
            breakout_vol = float(breakout_row['volume'])

            # 3. éªŒè¯è‡ªå¯åŠ¨ä»¥æ¥çš„æ•´ç†è´¨é‡ (Consolidation)
            consolidation_df = df.loc[breakout_date:].iloc[1:]
            if len(consolidation_df) < 2: 
                logger.debug(f"{code}: Consolidation period too short (<2 days)")
                return None
            
            # A. ç©ºé—´æ”¯æ’‘: æ”¶ç›˜ä»·ä¸åº”å¤§å¹…è·Œç ´å¯åŠ¨æ—¥æ”¶ç›˜ä»· (å…è®¸3%æµ®åŠ¨)
            min_close = pd.to_numeric(consolidation_df['close'], errors='coerce').min()
            if min_close < breakout_close * 0.97:
                logger.debug(f"{code}: Price drop too deep ({min_close} < {breakout_close * 0.97})")
                return None
            
            # B. è¶‹åŠ¿æ€§éªŒè¯: "æ¯æ—¥æ–°é«˜" æˆ– "Winè¿é˜³"
            # æ£€æŸ¥æ˜¯å¦æœ‰ win æŒ‡æ ‡ (cct å¤„ç†åçš„)
            if 'win' in consolidation_df.columns:
                recent_win = consolidation_df['win'].iloc[-3:]
                is_win_trend = (recent_win > 0).all() # æœ€è¿‘3æ—¥æ¸©å’Œä¸Šæ¶¨
            else:
                # æ‰‹åŠ¨åˆ¤å®š: æœ€è¿‘3æ—¥é«˜ç‚¹æ²¡æœ‰å¤§å¹…å›è½, ä¸”æœ‰å°è¯•åˆ›é«˜
                is_win_trend = (float(df.iloc[-1]['high']) > float(df.iloc[-3]['high']))

            # C. å‡çº¿æ”¯æ’‘: æœ€è¿‘1-2æ—¥ä½ç‚¹åº”è§¦åŠæˆ–æ¥è¿‘ MA10/MA20
            last_row = df.iloc[-1]
            ma10_val = float(last_row['ma10'])
            ma20_val = float(last_row['ma20'])
            ma5_val = float(last_row['ma5'])
            curr_low = float(last_row['low'])
            curr_close = float(last_row['close'])
            
            # æ”¯æ’‘åˆ¤å®š: ä½ç‚¹æ¥è¿‘10/20æ—¥çº¿ (2.5%èŒƒå›´å†…), ä¸”æ”¶ç›˜ç«™åœ¨5æ—¥çº¿ä¸Šæ–¹
            is_ma_supported = (curr_low < ma10_val * 1.025) or (curr_low < ma20_val * 1.025)
            # å¿…é¡»ç«™ç¨³5æ—¥çº¿
            if curr_close < ma5_val * 0.995: 
                logger.debug(f"{code}: Close below MA5 ({curr_close} < {ma5_val * 0.995})")
                return None
            
            if not is_ma_supported:
                # å¦‚æœæ²¡è§¦åŠå¤§å‡çº¿, æ£€æŸ¥æ˜¯å¦æ˜¯æå¼ºåŠ¿æ¨ªç›˜ (ä¸€ç›´åœ¨å¸ƒæ—ä¸Šè½¨é™„è¿‘)
                if not (curr_close > last_row['upper'] * 0.98):
                    logger.debug(f"{code}: Not touching MA support and not super strong ({curr_close} < {last_row['upper'] * 0.98})")
                    return None

            # 4. è“„åŠ¿å½¢æ€åˆ¤å®š (Setup Pattern)
            # A. ç¼©é‡: å½“å‰æˆäº¤é‡æ˜¾è‘—ä½äºå¯åŠ¨é‡ (æˆäº¤é‡èç¼©æ˜¯é‡ç‚¹)
            vol_curr = float(last_row['volume'])
            vol_ma5 = float(last_row['vol_ma5'])
            
            # æˆäº¤é‡å¿…é¡»å°äºå¯åŠ¨æ—¥çš„ 80% ä¸”å°äº5æ—¥å‡é‡
            is_shrinking = (vol_curr < breakout_vol * 0.8) and (vol_curr < vol_ma5 * 1.2)
            if not is_shrinking:
                logger.debug(f"{code}: Volume not shrinking enough ({vol_curr} vs {breakout_vol*0.8})")
                return None
            
            # B. Kçº¿å½¢æ€: åå­—æ˜Ÿæˆ–å°é˜³/å°é˜´ (æ•´ç†ä¸­)
            # å®ä½“è¾ƒå° æˆ– æ¶¨è·Œå¹…ç»å¯¹å€¼ < 2.5%
            body_abs = abs(curr_close - float(last_row['open']))
            is_small_k = (body_abs / curr_close < 0.025) or (abs(float(last_row['percent'])) < 2.5)
            
            if not (is_small_k and is_win_trend):
                logger.debug(f"{code}: K-Pattern mismatch (SmallK:{is_small_k}, WinTrend:{is_win_trend})")
                return None

            # 5. é¢å¤–è¿‡æ»¤: æ’é™¤åŠ é€Ÿèµ¶é¡¶
            # å¦‚æœæœ€è¿‘3æ—¥ç´¯è®¡æ¶¨å¹…è¿‡å¤§ï¼Œå¯èƒ½æ˜¯çªç ´åçš„äºŒæ³¢å·²ç»èµ°å®Œäº†
            recent_3_pct = consolidation_df['percent'].iloc[-3:].sum()
            if recent_3_pct > 15: 
                logger.debug(f"{code}: Accelerated too fast ({recent_3_pct} > 15)")
                return None

            return SignalPoint(
                code=code,
                signal_type=SignalType.BUY,
                timestamp=df.index[-1],
                bar_index=len(df)-1,
                price=curr_close,
                source=SignalSource.STRATEGY_ENGINE,
                reason=f"å¼ºåŠ¿ç¼©é‡å›è¸©: {breakout_date if isinstance(breakout_date, str) else breakout_date.strftime('%m-%d')}å¯åŠ¨, ç°ç¼©é‡è§¦åŠå‡çº¿æ”¯æ’‘"
            )
        except Exception as e:
            logger.debug(f"Pattern detect error for {code}: {e}")
            return None

