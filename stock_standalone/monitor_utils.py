# -*- coding:utf-8 -*-
import os
import json
import shutil
from datetime import datetime
from typing import List, Dict, Any, Optional, Union

# Note: These should ideally be imported or passed in. 
# For now, we will expect them to be provided or we'll define them here if they are static.

def load_display_config(config_file: str, default_cols: List[str]) -> Dict[str, Any]:
    """åŠ è½½æ˜¾ç¤ºé…ç½®"""
    if os.path.exists(config_file):
        with open(config_file, "r", encoding="utf-8") as f:
            try:
                return json.load(f)
            except json.JSONDecodeError:
                pass
    return {"current": default_cols, "sets": []}

def save_display_config(config_file: str, config: Dict[str, Any]) -> None:
    """ä¿å­˜æ˜¾ç¤ºé…ç½®"""
    with open(config_file, "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)

def save_monitor_list(monitor_list_file: str, monitor_windows_dict: Dict[str, Any], logger: Any) -> None:
    """ä¿å­˜å½“å‰çš„ç›‘æ§è‚¡ç¥¨åˆ—è¡¨åˆ°æ–‡ä»¶"""
    monitor_list = [win['stock_info'] for win in monitor_windows_dict.values()]
    mo_list = []
    if len(monitor_list) > 0:
        for m in monitor_list:
            stock_code = m[0]
            if stock_code:
                stock_code = stock_code.zfill(6)

            if not stock_code or len(stock_code) != 6 or not stock_code.isdigit():
                logger.info(f"é”™è¯¯è¯·è¾“å…¥æœ‰æ•ˆçš„6ä½è‚¡ç¥¨ä»£ç :{m}")
                continue
            
            # ç¡®ä¿ç»“æ„å‡çº§ï¼šå¸¦ create_time
            if len(m) < 4:
                create_time = datetime.now().strftime("%Y-%m-%d %H")
                m.append(create_time)
            mo_list.append(m)
            
        with open(monitor_list_file, "w", encoding="utf-8") as f:
            json.dump(mo_list, f, ensure_ascii=False, indent=2)
    else:
        logger.info('no window find')

    logger.info(f"ç›‘æ§åˆ—è¡¨å·²ä¿å­˜åˆ° {monitor_list_file} : count: {len(mo_list)}")

def load_monitor_list(monitor_list_file: str) -> List[List[Any]]:
    """ä»æ–‡ä»¶åŠ è½½ç›‘æ§è‚¡ç¥¨åˆ—è¡¨"""
    if os.path.exists(monitor_list_file):
        with open(monitor_list_file, "r", encoding="utf-8") as f:
            try:
                loaded_list = json.load(f)
                if isinstance(loaded_list, list) and all(isinstance(item, (list, tuple)) for item in loaded_list):
                    return [list(item) for item in loaded_list]
                return []
            except (json.JSONDecodeError, TypeError):
                return []
    return []

def list_archives(archive_dir: str, prefix: str = "search_history") -> List[str]:
    """åˆ—å‡ºæ‰€æœ‰å­˜æ¡£æ–‡ä»¶"""
    if not os.path.exists(archive_dir):
        return []
    files = sorted(
        [f for f in os.listdir(archive_dir) if f.startswith(prefix) and f.endswith(".json")],
        reverse=True
    )
    return files

def archive_file_tools(src_file: str, prefix: str, archive_dir: str, logger: Any, max_keep: int = 15) -> None:
    """é€šç”¨å¤‡ä»½å‡½æ•°"""
    if not os.path.exists(src_file):
        logger.info(f"âš  {src_file} ä¸å­˜åœ¨ï¼Œè·³è¿‡å­˜æ¡£")
        return

    try:
        with open(src_file, "r", encoding="utf-8") as f:
            content = f.read().strip()
    except Exception as e:
        logger.info(f"âš  æ— æ³•è¯»å– {src_file}: {e}")
        return

    if not content or content in ("[]", "{}", ""):
        logger.info(f"âš  {src_file} å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡å­˜æ¡£")
        return

    os.makedirs(archive_dir, exist_ok=True)

    files = sorted(
        [f for f in os.listdir(archive_dir) if f.startswith(prefix + "_")],
        reverse=True
    )

    if files:
        last_file = os.path.join(archive_dir, files[0])
        try:
            with open(last_file, "r", encoding="utf-8") as f:
                last_content = f.read().strip()
            if content == last_content:
                logger.info(f"âš  {src_file} ä¸ä¸Šä¸€æ¬¡ {prefix} å­˜æ¡£ç›¸åŒï¼Œè·³è¿‡å­˜æ¡£")
                return
        except Exception as e:
            logger.info(f"âš  æ— æ³•è¯»å–æœ€è¿‘å­˜æ¡£: {e}")

    today = datetime.now().strftime("%Y-%m-%d")
    filename = f"{prefix}_{today}.json"
    dest = os.path.join(archive_dir, filename)

    shutil.copy2(src_file, dest)
    logger.info(f"âœ… å·²å½’æ¡£ï¼š{os.path.relpath(dest)}")

    files = sorted(
        [os.path.join(archive_dir, f) for f in os.listdir(archive_dir) if f.startswith(prefix + "_")],
        key=os.path.getmtime,
        reverse=True
    )
    for old_file in files[max_keep:]:
        try:
            os.remove(old_file)
            logger.info(f"ğŸ—‘ åˆ é™¤æ—§å½’æ¡£: {os.path.basename(old_file)}")
        except Exception as e:
            logger.info(f"âš  åˆ é™¤å¤±è´¥ {old_file} -> {e}")

def archive_search_history_list(monitor_list_file: str, search_history_file: str, archive_dir: str, logger: Any) -> None:
    """å½’æ¡£ç›‘æ§æ–‡ä»¶ï¼Œé¿å…ç©ºæˆ–é‡å¤å­˜æ¡£"""
    archive_file_tools(monitor_list_file, "monitor_category_list", archive_dir, logger)

    if not os.path.exists(search_history_file):
        logger.info(f"âš  {search_history_file} ä¸å­˜åœ¨ï¼Œè·³è¿‡å½’æ¡£")
        return

    try:
        with open(search_history_file, "r", encoding="utf-8") as f:
            content = f.read().strip()
    except Exception as e:
        logger.info(f"âš  æ— æ³•è¯»å–ç›‘æ§æ–‡ä»¶: {e}")
        return

    if not content or content in ("[]", "{}"):
        logger.info(f"âš  {search_history_file} å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡å½’æ¡£")
        return

    os.makedirs(archive_dir, exist_ok=True)

    files = sorted(list_archives(archive_dir, "search_history"), reverse=True)
    if files:
        last_file = os.path.join(archive_dir, files[0])
        try:
            with open(last_file, "r", encoding="utf-8") as f:
                last_content = f.read().strip()
            if content == last_content:
                logger.info("âš  å†…å®¹ä¸ä¸Šä¸€æ¬¡å­˜æ¡£ç›¸åŒï¼Œè·³è¿‡å½’æ¡£")
                return
        except Exception as e:
            logger.info(f"âš  æ— æ³•è¯»å–æœ€è¿‘å­˜æ¡£: {e}")

    today = datetime.now().strftime("%Y-%m-%d-%H")
    filename = f"search_history_{today}.json"
    dest = os.path.join(archive_dir, filename)

    shutil.copy2(search_history_file, dest)
    logger.info(f"âœ… å·²å½’æ¡£ç›‘æ§æ–‡ä»¶: {dest}")

def ensure_parentheses_balanced(expr: str) -> str:
    """ç¡®ä¿è¡¨è¾¾å¼æ‹¬å·å¹³è¡¡ä¸”å¤–å±‚åŒ…è£¹"""
    expr = expr.strip()
    left_count = expr.count("(")
    right_count = expr.count(")")

    if left_count > right_count:
        expr += ")" * (left_count - right_count)
    elif right_count > left_count:
        expr = "(" * (right_count - left_count) + expr

    if not (expr.startswith("(") and expr.endswith(")")):
        expr = f"({expr})"
    return expr
